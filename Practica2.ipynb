{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "54ZTRELB_a_n",
        "outputId": "9d1ccc23-758c-4cab-e281-7ed1b49b1db5"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-8f448b10ea3f>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Lectura Archivo Local\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mruta2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"municipio.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mdf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mruta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Combinar los DataFrames en una Ãºnica tabla\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'municipio.csv'"
          ]
        }
      ],
      "source": [
        "# Importar librerÃ­as\n",
        "from sqlite3 import IntegrityError\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sqlalchemy import create_engine\n",
        "from sqlalchemy.exc import SQLAlchemyError\n",
        "\n",
        "# Lectura Archivo remoto\n",
        "ruta1 = \"https://seminario2.blob.core.windows.net/fase1/global.csv?sp=r&st=2023-12-06T03:45:26Z&se=2024-01-04T11:45:26Z&sv=2022-11-02&sr=b&sig=xdx7LdUOekGyBvGL%2FNE55ZZj9SBvCC%2FWegxtpSsKjJg%3D\"\n",
        "df1 = pd.read_csv(ruta1)\n",
        "\n",
        "# Lectura Archivo Local\n",
        "ruta2 = \"municipio.csv\"\n",
        "df2 = pd.read_csv(ruta2)\n",
        "\n",
        "# Combinar los DataFrames en una Ãºnica tabla\n",
        "combined_df = pd.concat([df1, df2], ignore_index=True)\n",
        "print(combined_df)\n",
        "combined_df = combined_df[combined_df['Country_code'] == 'GT']\n",
        "# Limpiar los datos\n",
        "# AquÃ­ puedes realizar operaciones de limpieza segÃºn tus necesidades\n",
        "# Por ejemplo, convertir la columna de fechas a formato datetime\n",
        "combined_df['Date_reported'] = pd.to_datetime(combined_df['Date_reported'], errors='coerce')\n",
        "\n",
        "\n",
        "# Filtrar datos del aÃ±o 2022\n",
        "#combined_df = combined_df[combined_df['Date_reported'].dt.year == 2022]\n",
        "\n",
        "# Nombre de las tablas propuestas\n",
        "fecha_table_name = 'Fecha'\n",
        "pais_table_name = 'Pais'\n",
        "informe_diario_table_name = 'InformeDiario'\n",
        "\n",
        "# ConexiÃ³n a la base de datos (reemplaza 'usuario', 'contraseÃ±a', 'localhost', 'nombre_de_base_de_datos')\n",
        "engine = create_engine('mysql://root:@localhost/seminario2')\n",
        "\n",
        "# Crear el DataFrame de la entidad \"Fecha\"\n",
        "fecha_df = pd.DataFrame({'Date_reported': combined_df['Date_reported']})\n",
        "\n",
        "# Crear el DataFrame de la entidad \"PaÃ­s\"\n",
        "pais_df = combined_df[['Country_code', 'Country', 'WHO_region']].drop_duplicates()\n",
        "\n",
        "# Crear el DataFrame de la entidad \"InformeDiario\"\n",
        "informe_diario_df = combined_df[['New_cases', 'Cumulative_cases', 'New_deaths', 'Cumulative_deaths']]\n",
        "\n",
        "# Crear relaciones\n",
        "relacion_fecha_informe = combined_df[['Date_reported']].merge(informe_diario_df, left_index=True, right_index=True)\n",
        "relacion_pais_informe = combined_df[['Country_code']].merge(informe_diario_df, left_index=True, right_index=True)\n",
        "\n",
        "# Definir las tablas y relaciones a insertar\n",
        "tables_to_insert = [\n",
        "    (fecha_df, fecha_table_name),\n",
        "    (pais_df, pais_table_name),\n",
        "    (informe_diario_df, informe_diario_table_name),\n",
        "    (relacion_fecha_informe, 'Relacion_Fecha_Informe'),\n",
        "    (relacion_pais_informe, 'Relacion_Pais_Informe'),\n",
        "]\n",
        "\n",
        "fecha_df = fecha_df.dropna()\n",
        "informe_diario_df = informe_diario_df.dropna()\n",
        "fecha_df = fecha_df.dropna()\n",
        "relacion_fecha_informe = relacion_fecha_informe.dropna()\n",
        "relacion_pais_informe = relacion_pais_informe.dropna()\n",
        "\n",
        "# Insertar en lotes de 50 registros\n",
        "#batch_size = 50\n",
        "\n",
        "#or df, table_name in tables_to_insert:\n",
        "#    for i in range(0, len(df), batch_size):\n",
        "#        batch = df.iloc[i:i + batch_size]\n",
        "#        batch.to_sql(table_name, con=engine, if_exists='append', index=False)\n",
        "#        print(f\"Lote insertado en {table_name}: {i + 1} - {i + len(batch)} de {len(df)}\")\n",
        "\n",
        "#print(\"InserciÃ³n de lotes completada.\")\n",
        "\n",
        "# Consultar datos de las tablas\n",
        "query_fecha = \"SELECT * FROM Fecha\"\n",
        "query_informe = \"SELECT * FROM InformeDiario\"\n",
        "query_pais = \"SELECT * FROM Pais\"\n",
        "query_relacion_fecha_informe = \"SELECT * FROM Relacion_Fecha_Informe\"\n",
        "query_relacion_pais_informe = \"SELECT * FROM Relacion_Pais_Informe\"\n",
        "\n",
        "df_fecha = pd.read_sql(query_fecha, engine)\n",
        "df_informe = pd.read_sql(query_informe, engine)\n",
        "df_pais = pd.read_sql(query_pais, engine)\n",
        "df_relacion_fecha_informe = pd.read_sql(query_relacion_fecha_informe, engine)\n",
        "df_relacion_pais_informe = pd.read_sql(query_relacion_pais_informe, engine)\n",
        "\n",
        "# EstadÃ­sticas descriptivas\n",
        "estadisticas_informe = df_informe.describe()\n",
        "estadisticas_pais = df_pais.describe()\n",
        "estadisticas_fecha = df_fecha.describe()\n",
        "\n",
        "# Histograma y diagrama de caja para InformeDiario\n",
        "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12, 8))\n",
        "\n",
        "# Nuevos casos\n",
        "sns.histplot(df_informe['New_cases'], kde=True, ax=axes[0, 0])\n",
        "axes[0, 0].set_title('Histograma - Nuevos Casos')\n",
        "\n",
        "# Casos acumulados\n",
        "sns.histplot(df_informe['Cumulative_cases'], kde=True, ax=axes[0, 1])\n",
        "axes[0, 1].set_title('Histograma - Casos Acumulados')\n",
        "\n",
        "# Nuevas muertes\n",
        "sns.histplot(df_informe['New_deaths'], kde=True, ax=axes[1, 0])\n",
        "axes[1, 0].set_title('Histograma - Nuevas Muertes')\n",
        "\n",
        "# Muertes acumuladas\n",
        "sns.histplot(df_informe['Cumulative_deaths'], kde=True, ax=axes[1, 1])\n",
        "axes[1, 1].set_title('Histograma - Muertes Acumuladas')\n",
        "\n",
        "# Ajustes de diseÃ±o\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Diagrama de caja para la poblaciÃ³n de los municipios (tabla Pais)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.boxplot(x=df_pais['Country_code'])\n",
        "plt.title('Diagrama de Barras - Country Code de los PaÃ­ses')\n",
        "plt.show()\n",
        "\n",
        "# Imprimir estadÃ­sticas descriptivas\n",
        "print(\"EstadÃ­sticas InformeDiario:\")\n",
        "print(estadisticas_informe)\n",
        "\n",
        "print(\"\\nEstadÃ­sticas Pais:\")\n",
        "print(estadisticas_pais)\n",
        "\n",
        "print(\"\\nEstadÃ­sticas Fecha:\")\n",
        "print(estadisticas_fecha)\n",
        "\n",
        "\n",
        "##Datos Cualitativos\n",
        "# Consulta SQL para obtener datos de la tabla `Pais`\n",
        "sql_query_pais = \"SELECT * FROM Pais\"\n",
        "\n",
        "# Ejecutar la consulta y cargar los resultados en un DataFrame\n",
        "df_pais = pd.read_sql_query(sql_query_pais, engine)\n",
        "\n",
        "# Conteo de registros por paÃ­s\n",
        "conteo_paises = df_pais['Country'].value_counts()\n",
        "\n",
        "# Crear diagrama de barras para paÃ­ses\n",
        "plt.figure(figsize=(12, 6))\n",
        "conteo_paises.plot(kind='bar', color='lightgreen')\n",
        "plt.title('Conteo de Registros por PaÃ­s')\n",
        "plt.xlabel('PaÃ­s')\n",
        "plt.ylabel('NÃºmero de Registros')\n",
        "plt.show()\n",
        "\n",
        "# Consultas SQL\n",
        "query_relacion_fecha_informe = \"SELECT * FROM Relacion_Fecha_Informe\"\n",
        "query_relacion_pais_informe = \"SELECT * FROM Relacion_Pais_Informe\"\n",
        "\n",
        "# Ejecutar las consultas y cargar los resultados en DataFrames\n",
        "df_relacion_fecha_informe = pd.read_sql(query_relacion_fecha_informe, con=engine)\n",
        "df_relacion_pais_informe = pd.read_sql(query_relacion_pais_informe, con=engine)\n",
        "\n",
        "# GrÃ¡ficas de dispersiÃ³n para datos cuantitativos\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "# Fecha vs cantidad de nuevas muertes\n",
        "plt.subplot(2, 2, 1)\n",
        "sns.scatterplot(x='Date_reported', y='New_deaths', data=df_relacion_fecha_informe)\n",
        "plt.title('Fecha vs Nuevas Muertes')\n",
        "\n",
        "# PaÃ­s vs cantidad de nuevas muertes\n",
        "plt.subplot(2, 2, 2)\n",
        "sns.scatterplot(x='Country_code', y='New_deaths', data=df_relacion_pais_informe)\n",
        "plt.title('PaÃ­s vs Nuevas Muertes')\n",
        "\n",
        "# Fecha vs cantidad de muertes acumuladas\n",
        "plt.subplot(2, 2, 3)\n",
        "sns.scatterplot(x='Date_reported', y='Cumulative_deaths', data=df_relacion_fecha_informe)\n",
        "plt.title('Fecha vs Muertes Acumuladas')\n",
        "\n",
        "# PaÃ­s vs cantidad de muertes acumuladas\n",
        "plt.subplot(2, 2, 4)\n",
        "sns.scatterplot(x='Country_code', y='Cumulative_deaths', data=df_relacion_pais_informe)\n",
        "plt.title('PaÃ­s vs Muertes Acumuladas')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# GrÃ¡ficas de barras para datos cualitativos\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "# Fecha vs cantidad de nuevas muertes\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.barplot(x='Date_reported', y='New_deaths', data=df_relacion_fecha_informe)\n",
        "plt.title('Fecha vs Nuevas Muertes')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "\n",
        "# PaÃ­s vs cantidad de nuevas muertes\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.barplot(x='Country_code', y='New_deaths', data=df_relacion_pais_informe)\n",
        "plt.title('PaÃ­s vs Nuevas Muertes')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n"
      ]
    }
  ]
}